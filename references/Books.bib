Automatically generated by Mendeley 1.0.1
Any changes to this file will be lost if it is regenerated by Mendeley.

@book{Bishop2006,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
author = {Bishop, Christopher M.},
booktitle = {Pattern Recognition},
doi = {10.1117/1.2819119},
editor = {Jordan, M and Kleinberg, J and Scholkopf, B},
file = {:Users/ondrejmandula/Library/Application Support/Mendeley Desktop/Downloaded/Bishop - 2006 - Pattern Recognition and Machine Learning.pdf:pdf},
isbn = {0387310738},
pages = {738},
publisher = {Springer},
title = {{Pattern Recognition and Machine Learning}},
year = {2006}
}
@book{Barber2010,
author = {Barber, David},
booktitle = {Machine Learning},
file = {:Users/ondrejmandula/Library/Application Support/Mendeley Desktop/Downloaded/Barber - 2010 - Bayesian Reasoning and Machine Learning.pdf:pdf},
title = {{Bayesian Reasoning and Machine Learning}},
year = {2010}
}
@book{MacKay2003,
abstract = {Information theory and inference, often taught separately, are here united in one entertaining textbook. These topics lie at the heart of many exciting areas of contemporary science and engineering - communication, signal processing, data mining, machine learning, pattern recognition, computational neuroscience, bioinformatics, and cryptography. This textbook introduces theory in tandem with applications. Information theory is taught alongside practical communication systems, such as arithmetic coding for data compression and sparse-graph codes for error-correction. A toolbox of inference techniques, including message-passing algorithms, Monte Carlo methods, and variational approximations, are developed alongside applications of these tools to clustering, convolutional codes, independent component analysis, and neural networks. The final part of the book describes the state of the art in error-correcting codes, including low-density parity-check codes, turbo codes, and digital fountain codes - the twenty-first century standards for satellite communications, disk drives, and data broadcast. Richly illustrated, filled with worked examples and over 400 exercises, some with detailed solutions, David MacKay's groundbreaking book is ideal for self-learning and for undergraduate or graduate courses. Interludes on crosswords, evolution, and sex provide entertainment along the way. In sum, this is a textbook on information, communication, and coding for a new generation of students, and an unparalleled entry point into these subjects for professionals in areas as diverse as computational biology, financial engineering, and machine learning.},
author = {MacKay, David J C},
booktitle = {Learning},
doi = {10.1017/S026357470426043X},
file = {:Users/ondrejmandula/Library/Application Support/Mendeley Desktop/Downloaded/Andrew - 2004 - INFORMATION THEORY, INFERENCE, AND LEARNING ALGORITHMS, by David J. C. MacKay, Cambridge University Press, Cambridge, 2003, hardback, xii 628 pp., ISBN 0-521-64298-1 (30.00).pdf:pdf},
institution = {Cambridge University},
isbn = {0521642981},
issn = {02635747},
number = {3},
pages = {628},
publisher = {Cambridge University Press},
title = {{Information Theory, Inference, and Learning Algorithms}},
url = {http://www.journals.cambridge.org/abstract_S026357470426043X},
volume = {22},
year = {2003}
}
